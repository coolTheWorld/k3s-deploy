"""AI Agentæ ¸å¿ƒ - ä½¿ç”¨ LangGraph API æ”¯æŒ AI Agents Debugger å¯è§†åŒ–"""
from langchain.agents import create_agent  # âœ… æ–°ç‰ˆ LangGraph API
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from pydantic import SecretStr
from typing import List

from .tools import K3sTools
from .prompts import SYSTEM_PROMPT, HEALTH_CHECK_PROMPT, DIAGNOSE_PROMPT, FIX_PROMPT
from ..rag.rag_engine import RAGEngine
from ..rag.knowledge_base import KnowledgeBaseManager
import logging
from datetime import datetime

logger = logging.getLogger(__name__)


class K3sHealthAgentRAG:
    """K3sé›†ç¾¤å¥åº·ç›‘æ§AI Agentï¼ˆå¯é€‰RAGå¢å¼ºï¼‰"""

    def __init__(self, api_key: str, cluster_config: dict, rag_config: dict = None, enable_rag: bool = False):
        logger.info("Initializing K3s Health Agent...")

        # self.llm = ChatOpenAI(
        #     model="gpt-4-turbo-preview",
        #     temperature=0,
        #     api_key=api_key
        # )
        self.llm = ChatOpenAI(
            api_key=SecretStr(api_key),
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            model="qwen-plus",  # Base URL
            temperature=0
        )

        # åˆå§‹åŒ–K3så·¥å…·é›†
        self.k3s_tools = K3sTools(cluster_config)

        # RAG å¼€å…³
        self.enable_rag = enable_rag
        self.rag_engine = None
        self.kb_manager = None

        # ä»…åœ¨å¯ç”¨ RAG æ—¶åˆå§‹åŒ–
        if self.enable_rag and rag_config:
            try:
                logger.info("Initializing RAG engine...")
                self.rag_engine = RAGEngine(rag_config)
                
                self.kb_manager = KnowledgeBaseManager(
                    self.rag_engine,
                    rag_config.get("knowledge_base_path", "./knowledge_base")
                )
                
                self.kb_manager.initialize_knowledge_base()
                logger.info("RAG engine initialized successfully")
            except Exception as e:
                logger.warning(f"Failed to initialize RAG engine (continuing without RAG): {e}")
                self.enable_rag = False
                self.rag_engine = None
                self.kb_manager = None
        else:
            logger.info("RAG engine disabled, running in basic mode")

        # æ‰‹åŠ¨ç®¡ç†èŠå¤©å†å²ï¼ˆæ›¿ä»£å·²å¼ƒç”¨çš„ ConversationBufferMemoryï¼‰
        self.chat_history: List = []

        # åˆ›å»ºAgent
        self.agent = self._create_agent()

        logger.info("K3s Health Agent initialized successfully")

    def _create_agent(self):
        """åˆ›å»º LangGraph Agentï¼ˆæ”¯æŒ AI Agents Debugger å¯è§†åŒ–ï¼‰"""

        # è·å–å·¥å…·åˆ—è¡¨
        tools = self.k3s_tools.get_tools()

        # âœ… ä½¿ç”¨æ–°ç‰ˆ LangGraph create_agent API
        # è¿™ä¸ª API ä¼šè¿”å›ä¸€ä¸ªå¯ä»¥åœ¨ AI Agents Debugger ä¸­å¯è§†åŒ–çš„çŠ¶æ€å›¾ Agent
        agent = create_agent(
            model=self.llm,
            tools=tools,
            system_prompt=SYSTEM_PROMPT,
            # LangGraph å†…éƒ¨è‡ªåŠ¨ç®¡ç†çŠ¶æ€å’Œæ¶ˆæ¯å†å²
        )

        logger.info(f"Created LangGraph agent with {len(tools)} tools (supports AI Agents Debugger visualization)")
        return agent
    
    def _log_tool_calls(self, output_messages, history_length):
        """æ‰“å°å·¥å…·è°ƒç”¨è¿‡ç¨‹çš„è¾…åŠ©æ–¹æ³•"""
        logger.info("ğŸ”§ å·¥å…·è°ƒç”¨è¿‡ç¨‹:")
        tool_call_count = 0
        
        # è·³è¿‡å†å²æ¶ˆæ¯å’Œè¾“å…¥æ¶ˆæ¯ï¼Œåªçœ‹æ–°çš„æ¶ˆæ¯
        for msg in output_messages[history_length + 1:]:
            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                for tool_call in msg.tool_calls:
                    tool_call_count += 1
                    logger.info(f"  [{tool_call_count}] è°ƒç”¨å·¥å…·: {tool_call.get('name', 'unknown')}")
                    logger.info(f"      å‚æ•°: {tool_call.get('args', {})}")
            elif hasattr(msg, 'content') and msg.content and not isinstance(msg, HumanMessage):
                # å·¥å…·è¿”å›çš„ç»“æœæˆ– AI çš„æ€è€ƒ
                if hasattr(msg, 'name'):  # å·¥å…·è¿”å›æ¶ˆæ¯
                    content_preview = msg.content[:200] + "..." if len(msg.content) > 200 else msg.content
                    logger.info(f"  â†³ å·¥å…·è¿”å›: {content_preview}")
        
        logger.info(f"ğŸ“Š æ€»å·¥å…·è°ƒç”¨æ¬¡æ•°: {tool_call_count}")
        logger.info("-" * 80)

    async def analyze_cluster_health(self) -> dict:
        """é›†ç¾¤å¥åº·æ£€æŸ¥ï¼ˆå¯é€‰RAGå¢å¼ºï¼‰"""
        try:
            # æ¡ä»¶æ€§ä½¿ç”¨ RAG
            if self.enable_rag and self.rag_engine:
                # RAG å¢å¼ºæ¨¡å¼
                best_practices = self.rag_engine.retrieve_best_practices(
                    "kubernetes cluster health check monitoring",
                    k=3
                )
                retrieved_context = self.rag_engine.format_retrieved_context(best_practices)
                
                full_input = f"""å½“å‰æ—¶é—´: {datetime.now().isoformat()}

ã€æ£€ç´¢åˆ°çš„ç›¸å…³çŸ¥è¯†ã€‘
{retrieved_context}

---

{HEALTH_CHECK_PROMPT}"""
                references = [doc.metadata for doc in best_practices]
            else:
                # åŸºç¡€æ¨¡å¼ï¼ˆæ—  RAGï¼‰
                full_input = f"""å½“å‰æ—¶é—´: {datetime.now().isoformat()}

{HEALTH_CHECK_PROMPT}"""
                references = []

            # âœ… LangGraph Agent ä½¿ç”¨ messages æ ¼å¼è°ƒç”¨
            # å°†å†å²æ¶ˆæ¯å’Œæ–°æ¶ˆæ¯ç»„åˆæˆå®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨
            messages = self.chat_history + [HumanMessage(content=full_input)]
            
            # æ‰“å°è¾“å…¥
            logger.info("=" * 80)
            logger.info("ğŸ”µ LLM è°ƒç”¨ - å¥åº·æ£€æŸ¥")
            logger.info("=" * 80)
            logger.info("ğŸ“‹ ç³»ç»Ÿæç¤º (SYSTEM_PROMPT):")
            logger.info(f"{SYSTEM_PROMPT}")
            logger.info("-" * 80)
            logger.info(f"ğŸ“¥ ç”¨æˆ·è¾“å…¥ (HEALTH_CHECK_PROMPT):\n{full_input}")
            logger.info("-" * 80)
            
            result = await self.agent.ainvoke(
                {"messages": messages},
                config={"recursion_limit": 50}  # å¢åŠ é€’å½’é™åˆ¶ï¼Œé˜²æ­¢è¿‡æ—©åœæ­¢
            )

            # æå– LangGraph è¿”å›çš„æ‰€æœ‰æ¶ˆæ¯
            output_messages = result.get("messages", [])
            
            # æ‰“å°å·¥å…·è°ƒç”¨è¿‡ç¨‹
            self._log_tool_calls(output_messages, len(self.chat_history))
            
            # æå–æœ€ç»ˆè¾“å‡º
            output = output_messages[-1].content if output_messages else ""
            
            # æ‰“å°æœ€ç»ˆè¾“å‡º
            logger.info(f"ğŸ“¤ æœ€ç»ˆè¾“å‡º:\n{output}")
            logger.info("=" * 80)

            # æ›´æ–°èŠå¤©å†å²
            self.chat_history.append(HumanMessage(content=full_input))
            self.chat_history.append(AIMessage(content=output))

            return {
                "status": "success",
                "analysis": output,
                "timestamp": datetime.now().isoformat(),
                "references": references,
                "rag_enabled": self.enable_rag
            }
        except Exception as e:
            logger.error(f"Health analysis failed: {e}")
            return {
                "status": "error",
                "error": str(e)
            }

    async def diagnose_issue(self, issue_description: str) -> dict:
        """é—®é¢˜è¯Šæ–­ï¼ˆå¯é€‰RAGå¢å¼ºï¼‰"""
        try:
            # æ¡ä»¶æ€§ä½¿ç”¨ RAG
            if self.enable_rag and self.rag_engine:
                # RAG å¢å¼ºæ¨¡å¼
                # æ£€ç´¢ç›¸ä¼¼çš„å†å²äº‹ä»¶
                similar_incidents = self.rag_engine.retrieve_similar_incidents(
                    issue_description,
                    k=3
                )

                # æ£€ç´¢ç›¸å…³è§£å†³æ–¹æ¡ˆ
                solutions = self.rag_engine.retrieve_solutions(
                    issue_description,
                    k=3
                )

                # æ£€ç´¢K8sæ–‡æ¡£
                k8s_docs = self.rag_engine.retrieve(
                    issue_description,
                    k=2,
                    filter_dict={"doc_type": "k8s_doc"}
                )

                # ç»„åˆæ£€ç´¢ç»“æœ
                all_docs = similar_incidents + solutions + k8s_docs
                retrieved_context = self.rag_engine.format_retrieved_context(all_docs)

                # æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å®Œæ•´è¾“å…¥
                full_input = f"""å½“å‰æ—¶é—´: {datetime.now().isoformat()}

ã€æ£€ç´¢åˆ°çš„ç›¸å…³çŸ¥è¯†ã€‘
{retrieved_context}

---

{DIAGNOSE_PROMPT.format(issue_description=issue_description)}"""

                # âœ… LangGraph Agent ä½¿ç”¨ messages æ ¼å¼è°ƒç”¨
                messages = self.chat_history + [HumanMessage(content=full_input)]
                
                # æ‰“å°è¾“å…¥
                logger.info("=" * 80)
                logger.info("ğŸ”µ LLM è°ƒç”¨ - é—®é¢˜è¯Šæ–­ (RAGæ¨¡å¼)")
                logger.info("=" * 80)
                logger.info("ğŸ“‹ ç³»ç»Ÿæç¤º (SYSTEM_PROMPT):")
                logger.info(f"{SYSTEM_PROMPT}")
                logger.info("-" * 80)
                logger.info(f"ğŸ“¥ ç”¨æˆ·è¾“å…¥ (å«RAGä¸Šä¸‹æ–‡):\n{full_input}")
                logger.info("-" * 80)
                
                result = await self.agent.ainvoke(
                    {"messages": messages},
                    config={"recursion_limit": 50}  # å¢åŠ é€’å½’é™åˆ¶
                )

                # æå–è¾“å‡º
                output_messages = result.get("messages", [])
                
                # æ‰“å°å·¥å…·è°ƒç”¨è¿‡ç¨‹
                self._log_tool_calls(output_messages, len(self.chat_history))
                
                output = output_messages[-1].content if output_messages else ""
                
                # æ‰“å°æœ€ç»ˆè¾“å‡º
                logger.info(f"ğŸ“¤ æœ€ç»ˆè¾“å‡º:\n{output}")
                logger.info("=" * 80)

                # æ›´æ–°èŠå¤©å†å²
                self.chat_history.append(HumanMessage(content=full_input))
                self.chat_history.append(AIMessage(content=output))

                return {
                    "status": "success",
                    "diagnosis": output,
                    "timestamp": datetime.now().isoformat(),
                    "similar_incidents": [
                        {
                            "id": doc.metadata.get("incident_id"),
                            "snippet": doc.page_content[:200] + "..."
                        }
                        for doc in similar_incidents
                    ],
                    "related_solutions": [
                        {
                            "id": doc.metadata.get("solution_id"),
                            "problem_type": doc.metadata.get("problem_type"),
                            "success_rate": doc.metadata.get("success_rate")
                        }
                        for doc in solutions
                    ],
                    "rag_enabled": True
                }
            else:
                # åŸºç¡€æ¨¡å¼ï¼ˆæ—  RAGï¼‰
                full_input = f"""å½“å‰æ—¶é—´: {datetime.now().isoformat()}

{DIAGNOSE_PROMPT.format(issue_description=issue_description)}"""

                # âœ… LangGraph Agent ä½¿ç”¨ messages æ ¼å¼è°ƒç”¨
                messages = self.chat_history + [HumanMessage(content=full_input)]
                
                # æ‰“å°è¾“å…¥
                logger.info("=" * 80)
                logger.info("ğŸ”µ LLM è°ƒç”¨ - é—®é¢˜è¯Šæ–­ (åŸºç¡€æ¨¡å¼)")
                logger.info("=" * 80)
                logger.info("ğŸ“‹ ç³»ç»Ÿæç¤º (SYSTEM_PROMPT):")
                logger.info(f"{SYSTEM_PROMPT}")
                logger.info("-" * 80)
                logger.info(f"ğŸ“¥ ç”¨æˆ·è¾“å…¥:\n{full_input}")
                logger.info("-" * 80)
                
                result = await self.agent.ainvoke(
                    {"messages": messages},
                    config={"recursion_limit": 50}  # å¢åŠ é€’å½’é™åˆ¶
                )

                # æå–è¾“å‡º
                output_messages = result.get("messages", [])
                
                # æ‰“å°å·¥å…·è°ƒç”¨è¿‡ç¨‹
                self._log_tool_calls(output_messages, len(self.chat_history))
                
                output = output_messages[-1].content if output_messages else ""
                
                # æ‰“å°æœ€ç»ˆè¾“å‡º
                logger.info(f"ğŸ“¤ æœ€ç»ˆè¾“å‡º:\n{output}")
                logger.info("=" * 80)

                # æ›´æ–°èŠå¤©å†å²
                self.chat_history.append(HumanMessage(content=full_input))
                self.chat_history.append(AIMessage(content=output))

                return {
                    "status": "success",
                    "diagnosis": output,
                    "timestamp": datetime.now().isoformat(),
                    "similar_incidents": [],
                    "related_solutions": [],
                    "rag_enabled": False
                }
        except Exception as e:
            logger.error(f"Diagnosis failed: {e}")
            return {
                "status": "error",
                "error": str(e)
            }

    async def auto_fix(self, issue: dict, auto_approve: bool = False) -> dict:
        """è‡ªåŠ¨ä¿®å¤ï¼ˆå¯é€‰RAGå¢å¼ºï¼‰"""
        if not auto_approve:
            return {
                "status": "pending_approval",
                "message": "éœ€è¦ç”¨æˆ·æ‰¹å‡†æ‰èƒ½æ‰§è¡Œä¿®å¤æ“ä½œ"
            }

        try:
            # æ¡ä»¶æ€§ä½¿ç”¨ RAG
            if self.enable_rag and self.rag_engine:
                # RAG å¢å¼ºæ¨¡å¼
                # æ£€ç´¢æˆåŠŸçš„è§£å†³æ–¹æ¡ˆ
                solutions = self.rag_engine.retrieve_solutions(
                    issue.get('description'),
                    k=3
                )

                retrieved_context = self.rag_engine.format_retrieved_context(solutions)

                # æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å®Œæ•´è¾“å…¥
                full_input = f"""å½“å‰æ—¶é—´: {datetime.now().isoformat()}

ã€æ£€ç´¢åˆ°çš„ç›¸å…³çŸ¥è¯†ã€‘
{retrieved_context}

---

{FIX_PROMPT.format(issue_description=issue.get('description'))}"""
            else:
                # åŸºç¡€æ¨¡å¼ï¼ˆæ—  RAGï¼‰
                full_input = f"""å½“å‰æ—¶é—´: {datetime.now().isoformat()}

{FIX_PROMPT.format(issue_description=issue.get('description'))}"""

            # âœ… LangGraph Agent ä½¿ç”¨ messages æ ¼å¼è°ƒç”¨
            messages = self.chat_history + [HumanMessage(content=full_input)]
            
            # æ‰“å°è¾“å…¥
            logger.info("=" * 80)
            logger.info(f"ğŸ”µ LLM è°ƒç”¨ - è‡ªåŠ¨ä¿®å¤ ({'RAGæ¨¡å¼' if self.enable_rag else 'åŸºç¡€æ¨¡å¼'})")
            logger.info("=" * 80)
            logger.info("ğŸ“‹ ç³»ç»Ÿæç¤º (SYSTEM_PROMPT):")
            logger.info(f"{SYSTEM_PROMPT}")
            logger.info("-" * 80)
            logger.info(f"ğŸ“¥ ç”¨æˆ·è¾“å…¥:\n{full_input}")
            logger.info("-" * 80)
            
            result = await self.agent.ainvoke(
                {"messages": messages},
                config={"recursion_limit": 50}  # å¢åŠ é€’å½’é™åˆ¶
            )

            # æå–è¾“å‡º
            output_messages = result.get("messages", [])
            
            # æ‰“å°å·¥å…·è°ƒç”¨è¿‡ç¨‹
            self._log_tool_calls(output_messages, len(self.chat_history))
            
            output = output_messages[-1].content if output_messages else ""
            
            # æ‰“å°æœ€ç»ˆè¾“å‡º
            logger.info(f"ğŸ“¤ æœ€ç»ˆè¾“å‡º:\n{output}")
            logger.info("=" * 80)

            # æ›´æ–°èŠå¤©å†å²
            self.chat_history.append(HumanMessage(content=full_input))
            self.chat_history.append(AIMessage(content=output))

            # è‡ªåŠ¨è®°å½•æˆåŠŸçš„ä¿®å¤åˆ°çŸ¥è¯†åº“ï¼ˆä»…åœ¨ RAG å¯ç”¨æ—¶ï¼‰
            if self.enable_rag and result.get("status") == "success":
                await self._record_successful_fix(issue, result)

            return {
                "status": "success",
                "fix_result": output,
                "timestamp": datetime.now().isoformat(),
                "rag_enabled": self.enable_rag
            }
        except Exception as e:
            logger.error(f"Auto fix failed: {e}")
            return {
                "status": "error",
                "error": str(e)
            }

    async def _record_successful_fix(self, issue: dict, fix_result: dict):
        """è®°å½•æˆåŠŸçš„ä¿®å¤åˆ°çŸ¥è¯†åº“"""
        try:
            incident = {
                "description": issue.get("description"),
                "severity": issue.get("severity", "medium"),
                "impact": issue.get("impact", "Unknown"),
                "root_cause": fix_result.get("root_cause", "Analyzing..."),
                "solution": fix_result.get("solution_steps", ""),
                "resolution_time": fix_result.get("resolution_time", "Unknown"),
                "resolved": True
            }

            self.kb_manager.add_incident(incident)
            logger.info(f"Recorded successful fix to knowledge base")

        except Exception as e:
            logger.error(f"Failed to record fix: {e}")

    def search_knowledge(self, query: str, k: int = 5) -> dict:
        """æœç´¢çŸ¥è¯†åº“"""
        # æ£€æŸ¥ RAG æ˜¯å¦å¯ç”¨
        if not self.enable_rag or not self.kb_manager:
            return {
                "status": "error",
                "error": "RAG engine is disabled. Enable RAG to use knowledge base search."
            }
        
        try:
            docs = self.kb_manager.search_knowledge_base(query, k=k)

            return {
                "status": "success",
                "results": [
                    {
                        "content": doc.page_content,
                        "metadata": doc.metadata
                    }
                    for doc in docs
                ],
                "count": len(docs)
            }
        except Exception as e:
            logger.error(f"Knowledge search failed: {e}")
            return {
                "status": "error",
                "error": str(e)
            }
